{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOkxNH29ivdBx2foRA56vFF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashkesharwani559/amazon_ml_challenge/blob/main/amazon_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install tesseract-ocr\n",
        "!pip install pytesseract opencv-python-headless pandas scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import pytesseract\n",
        "import cv2\n",
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Set the path for Tesseract executable (Optional: Update it according to your system)\n",
        "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # Default path for Tesseract in Colab\n",
        "\n",
        "# Function to download images from a URL\n",
        "def download_image(image_url, filename):\n",
        "    try:\n",
        "        urlretrieve(image_url, filename)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download image {image_url}: {e}\")\n",
        "\n",
        "# Function to preprocess image (Optional: Can be tuned for better OCR accuracy)\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        return None\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    return gray_image\n",
        "\n",
        "# Function to extract text from an image using Tesseract\n",
        "def extract_text_from_image(image_path):\n",
        "    processed_image = preprocess_image(image_path)\n",
        "    if processed_image is None:\n",
        "        return \"\"\n",
        "    text = pytesseract.image_to_string(processed_image)\n",
        "    return text\n",
        "\n",
        "# Function to prepare data for training\n",
        "def prepare_data(training_file):\n",
        "    df = pd.read_csv(training_file)\n",
        "\n",
        "    texts = []\n",
        "    labels = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        image_url = row['image_link']\n",
        "        entity_value = row['entity_value']\n",
        "        image_path = f\"/content/sample_data/images/{idx}.jpg\"  # Temp storage for the image\n",
        "\n",
        "        download_image(image_url, image_path)\n",
        "        text = extract_text_from_image(image_path)\n",
        "        texts.append(text)\n",
        "        labels.append(entity_value)\n",
        "\n",
        "    return texts, labels\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(training_file):\n",
        "    texts, labels = prepare_data(training_file)\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    labels_encoded = label_encoder.fit_transform(labels)\n",
        "\n",
        "    # Create a text processing and model pipeline\n",
        "    model = make_pipeline(\n",
        "        CountVectorizer(),  # Converts text to feature vectors\n",
        "        LogisticRegression(max_iter=1000)  # Basic classification model with increased iterations\n",
        "    )\n",
        "\n",
        "    # Train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(texts, labels_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Print model accuracy\n",
        "    print(f\"Model accuracy: {model.score(X_test, y_test) * 100:.2f}%\")\n",
        "\n",
        "    return model, label_encoder\n",
        "\n",
        "# Function to match text with allowed units (if applicable)\n",
        "def match_units(entity_name, extracted_text):\n",
        "    return extracted_text  # For now, simply returning the extracted text\n",
        "\n",
        "# Function to generate predictions for the entire test set\n",
        "def generate_predictions(test_file, output_file, model=None, label_encoder=None):\n",
        "    test_data = pd.read_csv(test_file)\n",
        "    predictions = []\n",
        "\n",
        "    for idx, row in test_data.iterrows():\n",
        "        image_url = row['image_link']\n",
        "        entity_name = row['entity_name']\n",
        "        index = row['index']\n",
        "\n",
        "        image_path = f\"temp_images/{index}.jpg\"\n",
        "        download_image(image_url, image_path)\n",
        "\n",
        "        extracted_text = extract_text_from_image(image_path)\n",
        "\n",
        "        if model and label_encoder:\n",
        "            # Use the trained model to predict the entity value\n",
        "            entity_value_prediction = model.predict([extracted_text])[0]\n",
        "            entity_value = label_encoder.inverse_transform([entity_value_prediction])[0]\n",
        "        else:\n",
        "            entity_value = row['entity_value']  # Use the actual value if no model\n",
        "\n",
        "        prediction = match_units(entity_name, extracted_text)\n",
        "\n",
        "        predictions.append({\"index\": index, \"prediction\": prediction})\n",
        "\n",
        "        print(f\"Index: {index}, Prediction: {prediction}\")\n",
        "\n",
        "    output_df = pd.DataFrame(predictions)\n",
        "    output_df.to_csv(output_file, index=False)\n",
        "    print(f\"Predictions saved to {output_file}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define file paths\n",
        "    training_file = \"/content/sample_data/dataset/train.csv\"\n",
        "    test_file = \"/content/sample_data/dataset/test.csv\"\n",
        "    output_file = \"/content/sample_data/dataset/test_out.csv\"\n",
        "\n",
        "    # Train the model with the entire dataset\n",
        "    model, label_encoder = train_model(training_file)\n",
        "\n",
        "    # Generate predictions for the entire test dataset\n",
        "    generate_predictions(test_file, output_file, model=model, label_encoder=label_encoder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fM_QNFv2q4c",
        "outputId": "a6394edb-7b8f-420e-fa9b-c76cb6cefd4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    }
  ]
}